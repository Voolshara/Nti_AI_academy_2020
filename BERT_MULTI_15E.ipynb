{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT_MULTI_15E.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f3811e0f2008400892ebab03a0505bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2603e9dd7f5b4fa9a1f9d1b3779eb549",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7992d354ff3441ee887e101caf05f893",
              "IPY_MODEL_a2e7163262a94e4a9dc2f1914c18b8b6"
            ]
          }
        },
        "2603e9dd7f5b4fa9a1f9d1b3779eb549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7992d354ff3441ee887e101caf05f893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08ae8308806e4a8ead3342da0e0562f9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9e8b5883dad491f85fa4018451de658"
          }
        },
        "a2e7163262a94e4a9dc2f1914c18b8b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c3810078253c4a41a19142579f5d6821",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:00&lt;00:00, 2.32MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_805f06258dbd409b87bc29585860621c"
          }
        },
        "08ae8308806e4a8ead3342da0e0562f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9e8b5883dad491f85fa4018451de658": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3810078253c4a41a19142579f5d6821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "805f06258dbd409b87bc29585860621c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6914a403bf1b49f187c2aab14380642d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7cdaf6b22dee48009cd2693dec69cda4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff94ddb4885048ab82d01327d5d1b397",
              "IPY_MODEL_4d39f9ae5b90428eb0fd16ede4d0d3c2"
            ]
          }
        },
        "7cdaf6b22dee48009cd2693dec69cda4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff94ddb4885048ab82d01327d5d1b397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1fc2d20d480c46099f6ed12763777089",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_06849dc9baef46f0a4973a69b84c49f5"
          }
        },
        "4d39f9ae5b90428eb0fd16ede4d0d3c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_67cb5603517e43e99071bd62aca35f18",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:00&lt;00:00, 2.22kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9bcf122efbf4b319f81e5cab520c49c"
          }
        },
        "1fc2d20d480c46099f6ed12763777089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "06849dc9baef46f0a4973a69b84c49f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67cb5603517e43e99071bd62aca35f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9bcf122efbf4b319f81e5cab520c49c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0df09f556f6943c7ad29d49e2da03ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c0601fdd4c464bedbed4dc006a07c91d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6f5c04bf675e4c2396a39d997bbd6880",
              "IPY_MODEL_f320990e41b1479dac1c2bc6b5b2bc13"
            ]
          }
        },
        "c0601fdd4c464bedbed4dc006a07c91d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f5c04bf675e4c2396a39d997bbd6880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6c42b5dba5eb434db57d82d5bf2ba38e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c602c4f6c66249d689ff7dbe031e057e"
          }
        },
        "f320990e41b1479dac1c2bc6b5b2bc13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7b05e67b9b884023a59ad45ac54b706b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 714M/714M [00:36&lt;00:00, 19.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dbd1cb6885da4f2a93581c4f3e177082"
          }
        },
        "6c42b5dba5eb434db57d82d5bf2ba38e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c602c4f6c66249d689ff7dbe031e057e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b05e67b9b884023a59ad45ac54b706b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dbd1cb6885da4f2a93581c4f3e177082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Voolshara/Nti_AI_academy_2020/blob/main/BERT_MULTI_15E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c60a8f12-6934-40a9-cbe6-cb1f84200d44"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e23ff87-efc2-40a4-ca69-a138ba339a64"
      },
      "source": [
        "!pip install transformers==3.0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\r\u001b[K     |▍                               | 10kB 28.6MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 15.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 13.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 12.2MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 8.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 8.8MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 8.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81kB 9.0MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 9.1MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102kB 9.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 133kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 153kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 163kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 174kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 184kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 194kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 204kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 215kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 225kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 245kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 256kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 266kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 276kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 286kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 296kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 307kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 317kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 337kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 348kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 358kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 368kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 378kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 389kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 399kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 409kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 419kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 430kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 440kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 450kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 460kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 471kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 481kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 491kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 501kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 512kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 522kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 532kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 542kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 552kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 563kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 573kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 583kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 593kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 604kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 614kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 624kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 634kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 645kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 655kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 665kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 675kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 686kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 696kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 706kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 716kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 727kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 737kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 747kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 757kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (3.0.12)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 16.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 46.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (1.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (20.8)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 56.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.0) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=a0883772747083f14ad52ce541eb409a5fd2f1279b151d96adb4fef01b950251\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.8.0rc4 transformers-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdO05qpJcr31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8453d744-544f-4b47-f442-2d980b94bb1d"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Front/NTI/main/semifinals/data/train.jsonl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-09 17:12:13--  https://raw.githubusercontent.com/AI-Front/NTI/main/semifinals/data/train.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2930172 (2.8M) [text/plain]\n",
            "Saving to: ‘train.jsonl’\n",
            "\n",
            "train.jsonl         100%[===================>]   2.79M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-01-09 17:12:13 (37.7 MB/s) - ‘train.jsonl’ saved [2930172/2930172]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehhg-KoKc0Wz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ee8c613-5e97-441c-a994-59243d8980cd"
      },
      "source": [
        "!wget  https://raw.githubusercontent.com/AI-Front/NTI/main/semifinals/data/val.jsonl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-09 17:12:13--  https://raw.githubusercontent.com/AI-Front/NTI/main/semifinals/data/val.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 566932 (554K) [text/plain]\n",
            "Saving to: ‘val.jsonl’\n",
            "\n",
            "\rval.jsonl             0%[                    ]       0  --.-KB/s               \rval.jsonl           100%[===================>] 553.64K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-01-09 17:12:14 (17.6 MB/s) - ‘val.jsonl’ saved [566932/566932]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jDy6s3wEFqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f002183-2e6f-46c3-e718-38200075e3eb"
      },
      "source": [
        "!wget  https://raw.githubusercontent.com/Voolshara/DS_NTI/main/test.jsonl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-09 17:12:14--  https://raw.githubusercontent.com/Voolshara/DS_NTI/main/test.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1739290 (1.7M) [text/plain]\n",
            "Saving to: ‘test.jsonl’\n",
            "\n",
            "test.jsonl          100%[===================>]   1.66M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2021-01-09 17:12:14 (17.5 MB/s) - ‘test.jsonl’ saved [1739290/1739290]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9nVW6zaETYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e0de279-ea52-4eea-8120-0b869cd513e1"
      },
      "source": [
        "!pip install jsonlines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/58/06f430ff7607a2929f80f07bfd820acbc508a4e977542fefcc522cde9dff/jsonlines-2.0.0-py3-none-any.whl\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiREodXuc3vF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe708bc-5cd3-4d3b-d272-eceac511a662"
      },
      "source": [
        "import json\r\n",
        "import jsonlines\r\n",
        "import codecs\r\n",
        "import os, re\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "%pylab inline\r\n",
        "from sklearn.metrics import *\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\r\n",
        "\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\r\n",
        "from sklearn.linear_model import SGDClassifier,LogisticRegression\r\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi3-1RvHc33J"
      },
      "source": [
        "def get_Data(data_json_file1, data_json_file2):\r\n",
        "    X, Y = [], []\r\n",
        "    with open(data_json_file1, 'r') as json_file:\r\n",
        "        json_list = list(json_file)\r\n",
        "        #print(json_list[0])\r\n",
        "        for json_str in json_list:\r\n",
        "            item = json.loads(json_str)\r\n",
        "            text = item['passage']['text']\r\n",
        "            #print(item['passage'].keys())\r\n",
        "            questions = item['passage']['questions']\r\n",
        "            for q in questions:\r\n",
        "                query = q['question']\r\n",
        "                ans = q['answers']\r\n",
        "                for a in ans:\r\n",
        "                  if len(text) <= 512:\r\n",
        "                    text_n = text\r\n",
        "                  else:\r\n",
        "                    text_n = text[-542:]   \r\n",
        "                  qw = query[:-1] if query[-1]==\".\" else query\r\n",
        "                  txt = a[\"text\"][:-1] if a[\"text\"][-1] == \".\" else a[\"text\"] \r\n",
        "                  X.append(\"[CLS]\" +text_n+ \"[SEP] \" +qw+ \" \" +txt)\r\n",
        "                  if a['label'] == 1:\r\n",
        "                    Y.append([0, 1])\r\n",
        "                  else:\r\n",
        "                    Y.append([1, 0])  \r\n",
        "                  #Y.append(a[\"label\"]) \r\n",
        "\r\n",
        "    with open(data_json_file2, 'r') as json_file:\r\n",
        "        json_list = list(json_file)\r\n",
        "        #print(json_list[0])\r\n",
        "        for json_str in json_list:\r\n",
        "            item = json.loads(json_str)\r\n",
        "            text = item['passage']['text']\r\n",
        "            #print(item['passage'].keys())\r\n",
        "            questions = item['passage']['questions']\r\n",
        "            for q in questions:\r\n",
        "                query = q['question']\r\n",
        "                ans = q['answers']\r\n",
        "                for a in ans:\r\n",
        "                  if len(text) <= 512:\r\n",
        "                    text_n = text\r\n",
        "                  else:\r\n",
        "                    text_n = text[-500:]   \r\n",
        "                  qw = query[:-1] if query[-1]==\".\" else query\r\n",
        "                  txt = a[\"text\"][:-1] if a[\"text\"][-1] == \".\" else a[\"text\"] \r\n",
        "                  X.append(\"[CLS]\" +text_n+ \"[SEP] \" +qw+ \" \" +txt)\r\n",
        "                  if a['label'] == 1:\r\n",
        "                    Y.append([0, 1])\r\n",
        "                  else:\r\n",
        "                    Y.append([1, 0])  \r\n",
        "                  #Y.append(a[\"label\"])                          \r\n",
        "    return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-Y8SlUJqGQb"
      },
      "source": [
        "Sentences, Labels = get_Data(\"/content/train.jsonl\", \"/content/val.jsonl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9Xb32E9rUEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd3c33ee-cec0-4201-c9ac-0ea734cb8c62"
      },
      "source": [
        "print(Sentences[100])\r\n",
        "print(len(Sentences), len(Sentences) == len(Labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS]участие в 11 матчах. (9) В среднем он отражает 90,5 процента бросков по своим воротам и пропускает по 3,1 шайбы за игру. (10) Один матч россиянин отстоял \"на ноль\". (11) Из других матчей, сыгранных в ночь на 8 ноября, стоит отметить победу \"Вашингтон Кэпиталс\" на \"Филадельфией Флайерс\" (3:2 в овертайме). (12) Нападающий \"Вашингтона\" Александр Семин забросил шайбу, а его одноклубник Александр Овечкин отдал голевой пас. (13) Один из голов \"Филадельфии\" на счету Николая Жердева Вратарь \"Флайерс\" Сергей Бобровский отразил 36 из 39 бросков.\"[SEP] Как Николай Хабибулин принес своей команде победу восьмого ноября в Чикаго? Он поймал все шайбы противника\n",
            "14185 True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq9lX1PLrex3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "f3811e0f2008400892ebab03a0505bc7",
            "2603e9dd7f5b4fa9a1f9d1b3779eb549",
            "7992d354ff3441ee887e101caf05f893",
            "a2e7163262a94e4a9dc2f1914c18b8b6",
            "08ae8308806e4a8ead3342da0e0562f9",
            "a9e8b5883dad491f85fa4018451de658",
            "c3810078253c4a41a19142579f5d6821",
            "805f06258dbd409b87bc29585860621c"
          ]
        },
        "outputId": "0e9499f6-42ce-4c42-9ddc-094d90a18a71"
      },
      "source": [
        "from transformers import BertTokenizer\r\n",
        "\r\n",
        "# Load the BERT tokenizer.\r\n",
        "print('Loading BERT tokenizer...')\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3811e0f2008400892ebab03a0505bc7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtKdfqA_r4__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e0f05f-e5bd-4c0c-a599-7513d46af9c2"
      },
      "source": [
        "R = Sentences[100]\r\n",
        "# Print the original sentence.\r\n",
        "print(' Original: ', R)\r\n",
        "\r\n",
        "# Print the sentence split into tokens.\r\n",
        "#print('Tokenized: ', tokenizer(R, return_tensors))\r\n",
        "print('Tokenized: ', tokenizer.tokenize(R, add_special_tokens=True))\r\n",
        "\r\n",
        "# Print the sentence mapped to token ids.\r\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(R)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keyword arguments {'add_special_tokens': True} not recognized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Original:  [CLS]участие в 11 матчах. (9) В среднем он отражает 90,5 процента бросков по своим воротам и пропускает по 3,1 шайбы за игру. (10) Один матч россиянин отстоял \"на ноль\". (11) Из других матчей, сыгранных в ночь на 8 ноября, стоит отметить победу \"Вашингтон Кэпиталс\" на \"Филадельфией Флайерс\" (3:2 в овертайме). (12) Нападающий \"Вашингтона\" Александр Семин забросил шайбу, а его одноклубник Александр Овечкин отдал голевой пас. (13) Один из голов \"Филадельфии\" на счету Николая Жердева Вратарь \"Флайерс\" Сергей Бобровский отразил 36 из 39 бросков.\"[SEP] Как Николай Хабибулин принес своей команде победу восьмого ноября в Чикаго? Он поймал все шайбы противника\n",
            "Tokenized:  ['[CLS]', 'участие', 'в', '11', 'матчах', '.', '(', '9', ')', 'в', 'среднем', 'он', 'от', '##ра', '##жает', '90', ',', '5', 'про', '##цент', '##а', 'бр', '##ос', '##ков', 'по', 'своим', 'ворота', '##м', 'и', 'про', '##пуска', '##ет', 'по', '3', ',', '1', 'ша', '##иб', '##ы', 'за', 'игру', '.', '(', '10', ')', 'один', 'матч', 'рос', '##сия', '##нин', 'отс', '##то', '##ял', '\"', 'на', 'но', '##ль', '\"', '.', '(', '11', ')', 'из', 'других', 'матче', '##и', ',', 'с', '##ыг', '##ран', '##ных', 'в', 'ночь', 'на', '8', 'ноября', ',', 'стоит', 'от', '##метить', 'победу', '\"', 'ва', '##шин', '##гт', '##он', 'к', '##э', '##пит', '##ал', '##с', '\"', 'на', '\"', 'ф', '##ила', '##дель', '##фи', '##еи', 'ф', '##ла', '##ие', '##рс', '\"', '(', '3', ':', '2', 'в', 'ове', '##рта', '##име', ')', '.', '(', '12', ')', 'напад', '##аю', '##щи', '##и', '\"', 'ва', '##шин', '##гт', '##она', '\"', 'але', '##кса', '##нд', '##р', 'семи', '##н', 'за', '##бр', '##ос', '##ил', 'ша', '##иб', '##у', ',', 'а', 'его', 'одно', '##кл', '##уб', '##ник', 'але', '##кса', '##нд', '##р', 'ове', '##чки', '##н', 'от', '##дал', 'гол', '##ево', '##и', 'па', '##с', '.', '(', '13', ')', 'один', 'из', 'голов', '\"', 'ф', '##ила', '##дель', '##фии', '\"', 'на', 'с', '##чет', '##у', 'ни', '##кол', '##ая', 'жерде', '##ва', 'в', '##рата', '##рь', '\"', 'ф', '##ла', '##ие', '##рс', '\"', 'се', '##рг', '##еи', 'бо', '##бр', '##овски', '##и', 'от', '##разил', '36', 'из', '39', 'бр', '##ос', '##ков', '.', '\"', '[SEP]', 'как', 'ни', '##кол', '##аи', 'х', '##аби', '##бул', '##ин', 'при', '##нес', 'св', '##ое', '##и', 'команде', 'победу', 'во', '##сь', '##мого', 'ноября', 'в', 'чи', '##ка', '##го', '?', 'он', 'по', '##има', '##л', 'все', 'ша', '##иб', '##ы', 'противника']\n",
            "Token IDs:  [101, 16635, 543, 10193, 34843, 119, 113, 130, 114, 543, 67606, 11060, 10332, 11079, 47546, 10919, 117, 126, 12709, 60515, 10179, 109300, 17969, 13036, 10297, 28365, 62516, 10241, 549, 12709, 54288, 11613, 10297, 124, 117, 122, 79703, 98446, 10292, 10234, 56762, 119, 113, 10150, 114, 13713, 33054, 28171, 25269, 19676, 103229, 10752, 29065, 107, 10122, 11279, 12118, 107, 119, 113, 10193, 114, 10387, 15597, 30158, 10191, 117, 558, 32307, 16346, 10970, 543, 60092, 10122, 129, 15452, 117, 75363, 10332, 88794, 42320, 107, 12450, 28483, 37876, 11579, 551, 18510, 80465, 12743, 10513, 107, 10122, 107, 561, 16610, 70835, 26245, 36694, 561, 10674, 12686, 45760, 107, 113, 124, 131, 123, 543, 46809, 26042, 54240, 114, 119, 113, 10186, 114, 78417, 103270, 19682, 10191, 107, 12450, 28483, 37876, 14614, 107, 13166, 57191, 16821, 10519, 76463, 10267, 10234, 85584, 17969, 13460, 79703, 98446, 10227, 117, 541, 10933, 41543, 53869, 40124, 11718, 13166, 57191, 16821, 10519, 46809, 14995, 10267, 10332, 28354, 25556, 42500, 10191, 12634, 10513, 119, 113, 10249, 114, 13713, 10387, 64371, 107, 561, 16610, 70835, 100380, 107, 10122, 558, 54697, 10227, 19544, 48613, 14655, 46070, 10852, 543, 38790, 28301, 107, 561, 10674, 12686, 45760, 107, 10277, 54841, 36694, 18481, 85584, 91945, 10191, 10332, 90402, 11055, 10387, 11303, 109300, 17969, 13036, 119, 107, 102, 10949, 19544, 48613, 35912, 562, 86840, 104037, 12029, 10913, 38157, 37629, 17117, 10191, 48769, 42320, 10439, 11833, 64608, 15452, 543, 17891, 10521, 10990, 136, 11060, 10297, 17804, 10517, 13686, 79703, 98446, 10292, 28471]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upin2pQwrpOI",
        "outputId": "6338679c-058c-4517-baf7-cdf96a58b8b5"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\r\n",
        "input_ids = []\r\n",
        "attention_masks = []\r\n",
        "\r\n",
        "# For every sentence...\r\n",
        "for sent in Sentences:\r\n",
        "    # `encode_plus` will:\r\n",
        "    #   (1) Tokenize the sentence.\r\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\r\n",
        "    #   (3) Append the `[SEP]` token to the end.\r\n",
        "    #   (4) Map tokens to their IDs.\r\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\r\n",
        "    #   (6) Create attention masks for [PAD] tokens.\r\n",
        "    encoded_dict = tokenizer.encode_plus(\r\n",
        "                        sent,                      # Sentence to encode.\r\n",
        "                        max_length = 468,           # Pad & truncate all sentences.\r\n",
        "                        pad_to_max_length = True,\r\n",
        "                        truncation=True,\r\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\r\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\r\n",
        "                        add_special_tokens = False, # Add '[CLS]' and '[SEP]'\r\n",
        "                   )\r\n",
        "    \r\n",
        "    # Add the encoded sentence to the list.    \r\n",
        "    input_ids.append(encoded_dict['input_ids'])\r\n",
        "    \r\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\r\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\r\n",
        "\r\n",
        "# Convert the lists into tensors.\r\n",
        "input_ids = torch.cat(input_ids, dim=0)\r\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\r\n",
        "labels = torch.tensor(Labels)\r\n",
        "\r\n",
        "# Print sentence 0, now as a list of IDs.\r\n",
        "print('Original: ', Sentences[0])\r\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  [CLS]к они, слипшиеся, неподъёмно и лежали. (7) Да и не ради причёски приходил парень к Людочке. (8) Как только её руки становились занятыми ножницами и расчёской, Артемка начинал хватать её за разные места. (9) Людочка сначала увёртывалась от хватких рук Артемки, а когда не помогло, стукнула его машинкой по голове и пробила до крови, пришлось лить йод на голову «ухажористого человека». (10) Артемка заулюлюкал и со свистом стал ловить воздух. (11) С тех пор «домогания свои хулиганские прекратил», более того, шпане повелел Людочку не трогать.[SEP] Где бегала шпана? В парке\n",
            "Token IDs: tensor([   101,    551,  14274,    117,  52399,  30637,  78152,    117,  10375,\n",
            "         53204,  10746,  30318,  12579,  10636,    549,  94693,  48873,    119,\n",
            "           113,    128,    114,  10405,    549,  10375,  18701,  10913,  24373,\n",
            "         10913,  82005,  66457,  19557,    551,    552,  10593,  17961,  19347,\n",
            "           119,    113,    129,    114,  10949,  13721,  75431,  50365,  66345,\n",
            "         71728,  11833,  10234,  87455,  21473,  11279,  40703,  34237,    549,\n",
            "           557,  18291,  53562,  10191,    117,  40585,  10696,  63861,  27353,\n",
            "         12743,    562,  35282,  11258,  75431,  10234,  79162,  19442,    119,\n",
            "           113,    130,    114,    552,  10593,  17961,  15116,  51174,    560,\n",
            "         32418,  12202,  63967,  10332,    562,  18741,  18050,  84043,  40585,\n",
            "         10696,  54929,    117,    541,  15283,  10375,  96358,  18442,  11602,\n",
            "           117,  15888,  20216, 103614,  10933,  51290,  11623,  10191,  10297,\n",
            "         64371,  10205,    549,  12709,  50519,  10344,  83191,    117,  64336,\n",
            "         99197,  10851,    549,  16625,  10122,  83603,    208,    560,  16183,\n",
            "         52834,  62261,  12470,  18035,    220,    119,    113,  10150,    114,\n",
            "         40585,  10696,  63861,  10234,  18126,  10593,  21190,  48225,    549,\n",
            "         10956,  60763,  54853,  13462,  30977,  60797,  10439,  86537,    119,\n",
            "           113,  10193,    114,    558,  32323,  41436,    208,  21487,  36666,\n",
            "         12268,  22003,    562,  30102,  14814,  14354,  38494,  10510,  77002,\n",
            "           220,    117,  13106,  12409,    117,  13568,  30201,  30148,  31851,\n",
            "         10517,    552,  10593,  17961,  33755,  10375,    559,  84349,  11258,\n",
            "           119,    102,  12252,    542,  48372,  10674,  13568,  14622,    136,\n",
            "           543,  31667,  10205,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueHVnN_14OIL",
        "outputId": "b04b26d0-70b2-4760-f24b-59cbdcc0bf00"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\r\n",
        "\r\n",
        "# Combine the training inputs into a TensorDataset.\r\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\r\n",
        "\r\n",
        "# Create a 90-10 train-validation split.\r\n",
        "\r\n",
        "# Calculate the number of samples to include in each set.\r\n",
        "train_size = int(0.9 * len(dataset))\r\n",
        "val_size = len(dataset) - train_size\r\n",
        "\r\n",
        "# Divide the dataset by randomly selecting samples.\r\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\r\n",
        "\r\n",
        "print('{:>5,} training samples'.format(train_size))\r\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12,766 training samples\n",
            "1,419 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBJT05co4OW0"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\r\n",
        "\r\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \r\n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \r\n",
        "# size of 16 or 32.\r\n",
        "batch_size = 8\r\n",
        "\r\n",
        "# Create the DataLoaders for our training and validation sets.\r\n",
        "# We'll take training samples in random order. \r\n",
        "train_dataloader = DataLoader(\r\n",
        "            train_dataset,  # The training samples.\r\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\r\n",
        "            batch_size = batch_size # Trains with this batch size.\r\n",
        "        )\r\n",
        "\r\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\r\n",
        "validation_dataloader = DataLoader(\r\n",
        "            val_dataset, # The validation samples.\r\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\r\n",
        "            batch_size = batch_size # Evaluate with this batch size.\r\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6914a403bf1b49f187c2aab14380642d",
            "7cdaf6b22dee48009cd2693dec69cda4",
            "ff94ddb4885048ab82d01327d5d1b397",
            "4d39f9ae5b90428eb0fd16ede4d0d3c2",
            "1fc2d20d480c46099f6ed12763777089",
            "06849dc9baef46f0a4973a69b84c49f5",
            "67cb5603517e43e99071bd62aca35f18",
            "f9bcf122efbf4b319f81e5cab520c49c",
            "0df09f556f6943c7ad29d49e2da03ff2",
            "c0601fdd4c464bedbed4dc006a07c91d",
            "6f5c04bf675e4c2396a39d997bbd6880",
            "f320990e41b1479dac1c2bc6b5b2bc13",
            "6c42b5dba5eb434db57d82d5bf2ba38e",
            "c602c4f6c66249d689ff7dbe031e057e",
            "7b05e67b9b884023a59ad45ac54b706b",
            "dbd1cb6885da4f2a93581c4f3e177082"
          ]
        },
        "id": "6ug_RMo24OZC",
        "outputId": "594e0a9d-180a-4167-a911-747098388265"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\r\n",
        "\r\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \r\n",
        "# linear classification layer on top. \r\n",
        "model = BertForSequenceClassification.from_pretrained(\r\n",
        "    \"bert-base-multilingual-cased\", # Use the 12-layer BERT model, with an uncased vocab.\r\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\r\n",
        "                    # You can increase this for multi-class tasks.   \r\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\r\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\r\n",
        ")\r\n",
        "\r\n",
        "# Tell pytorch to run this model on the GPU.\r\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6914a403bf1b49f187c2aab14380642d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0df09f556f6943c7ad29d49e2da03ff2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq6SQpa44YUM"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \r\n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\r\n",
        "optimizer = AdamW(model.parameters(),\r\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\r\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\r\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAVAS6KD4-E_"
      },
      "source": [
        "epochs = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNp4uUz54YWj"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\r\n",
        "\r\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \r\n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\r\n",
        "# training data.\r\n",
        "\r\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \r\n",
        "# (Note that this is not the same as the number of training samples).\r\n",
        "total_steps = len(train_dataloader) * epochs\r\n",
        "\r\n",
        "# Create the learning rate scheduler.\r\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \r\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\r\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHCoP1kT4YZH"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "# Function to calculate the accuracy of our predictions vs labels\r\n",
        "def flat_accuracy(preds, labels):\r\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\r\n",
        "    labels_flat = labels.flatten()\r\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTJscvgY4weH"
      },
      "source": [
        "import time\r\n",
        "import datetime\r\n",
        "\r\n",
        "def format_time(elapsed):\r\n",
        "    '''\r\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\r\n",
        "    '''\r\n",
        "    # Round to the nearest second.\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    \r\n",
        "    # Format as hh:mm:ss\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1JbWKMb4wgC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e2f8134-84dc-4ac4-9f75-2d5b56d9fba9"
      },
      "source": [
        "import random\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# This training code is based on the `run_glue.py` script here:\r\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\r\n",
        "\r\n",
        "# Set the seed value all over the place to make this reproducible.\r\n",
        "seed_val = 42\r\n",
        "\r\n",
        "random.seed(seed_val)\r\n",
        "np.random.seed(seed_val)\r\n",
        "torch.manual_seed(seed_val)\r\n",
        "torch.cuda.manual_seed_all(seed_val)\r\n",
        "\r\n",
        "# We'll store a number of quantities such as training and validation loss, \r\n",
        "# validation accuracy, and timings.\r\n",
        "training_stats = []\r\n",
        "\r\n",
        "# Measure the total training time for the whole run.\r\n",
        "total_t0 = time.time()\r\n",
        "\r\n",
        "# For each epoch...\r\n",
        "for epoch_i in range(0, epochs):\r\n",
        "    \r\n",
        "    # ========================================\r\n",
        "    #               Training\r\n",
        "    # ========================================\r\n",
        "    \r\n",
        "    # Perform one full pass over the training set.\r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\r\n",
        "    print('Training...')\r\n",
        "\r\n",
        "    # Measure how long the training epoch takes.\r\n",
        "    t0 = time.time()\r\n",
        "\r\n",
        "    # Reset the total loss for this epoch.\r\n",
        "    total_train_loss = 0\r\n",
        "\r\n",
        "    # Put the model into training mode. Don't be mislead--the call to \r\n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\r\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\r\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\r\n",
        "    model.train()\r\n",
        "\r\n",
        "    # For each batch of training data...\r\n",
        "    for step, batch in enumerate(train_dataloader):\r\n",
        "\r\n",
        "        # Progress update every 40 batches.\r\n",
        "        if step % 40 == 0 and not step == 0:\r\n",
        "            # Calculate elapsed time in minutes.\r\n",
        "            elapsed = format_time(time.time() - t0)\r\n",
        "            \r\n",
        "            # Report progress.\r\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\r\n",
        "\r\n",
        "        # Unpack this training batch from our dataloader. \r\n",
        "        #\r\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \r\n",
        "        # `to` method.\r\n",
        "        #\r\n",
        "        # `batch` contains three pytorch tensors:\r\n",
        "        #   [0]: input ids \r\n",
        "        #   [1]: attention masks\r\n",
        "        #   [2]: labels \r\n",
        "        b_input_ids = batch[0].to(device)\r\n",
        "        b_input_mask = batch[1].to(device)\r\n",
        "        b_labels = batch[2].to(device)\r\n",
        "\r\n",
        "        # Always clear any previously calculated gradients before performing a\r\n",
        "        # backward pass. PyTorch doesn't do this automatically because \r\n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \r\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\r\n",
        "        model.zero_grad()        \r\n",
        "\r\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\r\n",
        "        # The documentation for this `model` function is here: \r\n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\r\n",
        "        # It returns different numbers of parameters depending on what arguments\r\n",
        "        # arge given and what flags are set. For our useage here, it returns\r\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\r\n",
        "        # outputs prior to activation.\r\n",
        "        loss, logits = model(b_input_ids, \r\n",
        "                             token_type_ids=None, \r\n",
        "                             attention_mask=b_input_mask, \r\n",
        "                             labels=b_labels)\r\n",
        "\r\n",
        "        # Accumulate the training loss over all of the batches so that we can\r\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\r\n",
        "        # single value; the `.item()` function just returns the Python value \r\n",
        "        # from the tensor.\r\n",
        "        total_train_loss += loss.item()\r\n",
        "\r\n",
        "        # Perform a backward pass to calculate the gradients.\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        # Clip the norm of the gradients to 1.0.\r\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "\r\n",
        "        # Update parameters and take a step using the computed gradient.\r\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\r\n",
        "        # modified based on their gradients, the learning rate, etc.\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        # Update the learning rate.\r\n",
        "        scheduler.step()\r\n",
        "\r\n",
        "    # Calculate the average loss over all of the batches.\r\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \r\n",
        "    \r\n",
        "    # Measure how long this epoch took.\r\n",
        "    training_time = format_time(time.time() - t0)\r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\r\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\r\n",
        "        \r\n",
        "    # ========================================\r\n",
        "    #               Validation\r\n",
        "    # ========================================\r\n",
        "    # After the completion of each training epoch, measure our performance on\r\n",
        "    # our validation set.\r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"Running Validation...\")\r\n",
        "\r\n",
        "    t0 = time.time()\r\n",
        "\r\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\r\n",
        "    # during evaluation.\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    # Tracking variables \r\n",
        "    total_eval_accuracy = 0\r\n",
        "    total_eval_loss = 0\r\n",
        "    nb_eval_steps = 0\r\n",
        "\r\n",
        "    # Evaluate data for one epoch\r\n",
        "    for batch in validation_dataloader:\r\n",
        "        \r\n",
        "        # Unpack this training batch from our dataloader. \r\n",
        "        #\r\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \r\n",
        "        # the `to` method.\r\n",
        "        #\r\n",
        "        # `batch` contains three pytorch tensors:\r\n",
        "        #   [0]: input ids \r\n",
        "        #   [1]: attention masks\r\n",
        "        #   [2]: labels \r\n",
        "        b_input_ids = batch[0].to(device)\r\n",
        "        b_input_mask = batch[1].to(device)\r\n",
        "        b_labels = batch[2].to(device)\r\n",
        "        \r\n",
        "        # Tell pytorch not to bother with constructing the compute graph during\r\n",
        "        # the forward pass, since this is only needed for backprop (training).\r\n",
        "        with torch.no_grad():        \r\n",
        "\r\n",
        "            # Forward pass, calculate logit predictions.\r\n",
        "            # token_type_ids is the same as the \"segment ids\", which \r\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\r\n",
        "            # The documentation for this `model` function is here: \r\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\r\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\r\n",
        "            # values prior to applying an activation function like the softmax.\r\n",
        "            (loss, logits) = model(b_input_ids, \r\n",
        "                                   token_type_ids=None, \r\n",
        "                                   attention_mask=b_input_mask,\r\n",
        "                                   labels=b_labels)\r\n",
        "            \r\n",
        "        # Accumulate the validation loss.\r\n",
        "        total_eval_loss += loss.item()\r\n",
        "\r\n",
        "        # Move logits and labels to CPU\r\n",
        "        logits = logits.detach().cpu().numpy()\r\n",
        "        label_ids = b_labels.to('cpu').numpy()\r\n",
        "\r\n",
        "        # Calculate the accuracy for this batch of test sentences, and\r\n",
        "        # accumulate it over all batches.\r\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\r\n",
        "        \r\n",
        "\r\n",
        "    # Report the final accuracy for this validation run.\r\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\r\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\r\n",
        "\r\n",
        "    # Calculate the average loss over all of the batches.\r\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\r\n",
        "    \r\n",
        "    # Measure how long the validation run took.\r\n",
        "    validation_time = format_time(time.time() - t0)\r\n",
        "    \r\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\r\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\r\n",
        "\r\n",
        "    # Record all statistics from this epoch.\r\n",
        "    training_stats.append(\r\n",
        "        {\r\n",
        "            'epoch': epoch_i + 1,\r\n",
        "            'Training Loss': avg_train_loss,\r\n",
        "            'Valid. Loss': avg_val_loss,\r\n",
        "            'Valid. Accur.': avg_val_accuracy,\r\n",
        "            'Training Time': training_time,\r\n",
        "            'Validation Time': validation_time\r\n",
        "        }\r\n",
        "    )\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"Training complete!\")\r\n",
        "\r\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 15 ========\n",
            "Training...\n",
            "  Batch    40  of  1,596.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  1,596.    Elapsed: 0:00:36.\n",
            "  Batch   120  of  1,596.    Elapsed: 0:00:54.\n",
            "  Batch   160  of  1,596.    Elapsed: 0:01:12.\n",
            "  Batch   200  of  1,596.    Elapsed: 0:01:30.\n",
            "  Batch   240  of  1,596.    Elapsed: 0:01:48.\n",
            "  Batch   280  of  1,596.    Elapsed: 0:02:06.\n",
            "  Batch   320  of  1,596.    Elapsed: 0:02:24.\n",
            "  Batch   360  of  1,596.    Elapsed: 0:02:42.\n",
            "  Batch   400  of  1,596.    Elapsed: 0:03:00.\n",
            "  Batch   440  of  1,596.    Elapsed: 0:03:18.\n",
            "  Batch   480  of  1,596.    Elapsed: 0:03:36.\n",
            "  Batch   520  of  1,596.    Elapsed: 0:03:54.\n",
            "  Batch   560  of  1,596.    Elapsed: 0:04:12.\n",
            "  Batch   600  of  1,596.    Elapsed: 0:04:29.\n",
            "  Batch   640  of  1,596.    Elapsed: 0:04:47.\n",
            "  Batch   680  of  1,596.    Elapsed: 0:05:05.\n",
            "  Batch   720  of  1,596.    Elapsed: 0:05:23.\n",
            "  Batch   760  of  1,596.    Elapsed: 0:05:41.\n",
            "  Batch   800  of  1,596.    Elapsed: 0:05:59.\n",
            "  Batch   840  of  1,596.    Elapsed: 0:06:17.\n",
            "  Batch   880  of  1,596.    Elapsed: 0:06:35.\n",
            "  Batch   920  of  1,596.    Elapsed: 0:06:53.\n",
            "  Batch   960  of  1,596.    Elapsed: 0:07:11.\n",
            "  Batch 1,000  of  1,596.    Elapsed: 0:07:29.\n",
            "  Batch 1,040  of  1,596.    Elapsed: 0:07:47.\n",
            "  Batch 1,080  of  1,596.    Elapsed: 0:08:05.\n",
            "  Batch 1,120  of  1,596.    Elapsed: 0:08:23.\n",
            "  Batch 1,160  of  1,596.    Elapsed: 0:08:41.\n",
            "  Batch 1,200  of  1,596.    Elapsed: 0:08:59.\n",
            "  Batch 1,240  of  1,596.    Elapsed: 0:09:17.\n",
            "  Batch 1,280  of  1,596.    Elapsed: 0:09:34.\n",
            "  Batch 1,320  of  1,596.    Elapsed: 0:09:52.\n",
            "  Batch 1,360  of  1,596.    Elapsed: 0:10:10.\n",
            "  Batch 1,400  of  1,596.    Elapsed: 0:10:28.\n",
            "  Batch 1,440  of  1,596.    Elapsed: 0:10:46.\n",
            "  Batch 1,480  of  1,596.    Elapsed: 0:11:04.\n",
            "  Batch 1,520  of  1,596.    Elapsed: 0:11:22.\n",
            "  Batch 1,560  of  1,596.    Elapsed: 0:11:40.\n",
            "\n",
            "  Average training loss: 0.66\n",
            "  Training epcoh took: 0:11:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.66\n",
            "  Validation took: 0:00:25\n",
            "\n",
            "======== Epoch 2 / 15 ========\n",
            "Training...\n",
            "  Batch    40  of  1,596.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  1,596.    Elapsed: 0:00:36.\n",
            "  Batch   120  of  1,596.    Elapsed: 0:00:54.\n",
            "  Batch   160  of  1,596.    Elapsed: 0:01:12.\n",
            "  Batch   200  of  1,596.    Elapsed: 0:01:30.\n",
            "  Batch   240  of  1,596.    Elapsed: 0:01:48.\n",
            "  Batch   280  of  1,596.    Elapsed: 0:02:06.\n",
            "  Batch   320  of  1,596.    Elapsed: 0:02:23.\n",
            "  Batch   360  of  1,596.    Elapsed: 0:02:41.\n",
            "  Batch   400  of  1,596.    Elapsed: 0:02:59.\n",
            "  Batch   440  of  1,596.    Elapsed: 0:03:17.\n",
            "  Batch   480  of  1,596.    Elapsed: 0:03:35.\n",
            "  Batch   520  of  1,596.    Elapsed: 0:03:53.\n",
            "  Batch   560  of  1,596.    Elapsed: 0:04:11.\n",
            "  Batch   600  of  1,596.    Elapsed: 0:04:29.\n",
            "  Batch   640  of  1,596.    Elapsed: 0:04:47.\n",
            "  Batch   680  of  1,596.    Elapsed: 0:05:05.\n",
            "  Batch   720  of  1,596.    Elapsed: 0:05:23.\n",
            "  Batch   760  of  1,596.    Elapsed: 0:05:41.\n",
            "  Batch   800  of  1,596.    Elapsed: 0:05:59.\n",
            "  Batch   840  of  1,596.    Elapsed: 0:06:17.\n",
            "  Batch   880  of  1,596.    Elapsed: 0:06:35.\n",
            "  Batch   920  of  1,596.    Elapsed: 0:06:53.\n",
            "  Batch   960  of  1,596.    Elapsed: 0:07:10.\n",
            "  Batch 1,000  of  1,596.    Elapsed: 0:07:28.\n",
            "  Batch 1,040  of  1,596.    Elapsed: 0:07:46.\n",
            "  Batch 1,080  of  1,596.    Elapsed: 0:08:04.\n",
            "  Batch 1,120  of  1,596.    Elapsed: 0:08:22.\n",
            "  Batch 1,160  of  1,596.    Elapsed: 0:08:40.\n",
            "  Batch 1,200  of  1,596.    Elapsed: 0:08:58.\n",
            "  Batch 1,240  of  1,596.    Elapsed: 0:09:16.\n",
            "  Batch 1,280  of  1,596.    Elapsed: 0:09:34.\n",
            "  Batch 1,320  of  1,596.    Elapsed: 0:09:52.\n",
            "  Batch 1,360  of  1,596.    Elapsed: 0:10:10.\n",
            "  Batch 1,400  of  1,596.    Elapsed: 0:10:28.\n",
            "  Batch 1,440  of  1,596.    Elapsed: 0:10:46.\n",
            "  Batch 1,480  of  1,596.    Elapsed: 0:11:04.\n",
            "  Batch 1,520  of  1,596.    Elapsed: 0:11:21.\n",
            "  Batch 1,560  of  1,596.    Elapsed: 0:11:39.\n",
            "\n",
            "  Average training loss: 0.66\n",
            "  Training epcoh took: 0:11:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.62\n",
            "  Validation Loss: 0.67\n",
            "  Validation took: 0:00:25\n",
            "\n",
            "======== Epoch 3 / 15 ========\n",
            "Training...\n",
            "  Batch    40  of  1,596.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  1,596.    Elapsed: 0:00:36.\n",
            "  Batch   120  of  1,596.    Elapsed: 0:00:54.\n",
            "  Batch   160  of  1,596.    Elapsed: 0:01:12.\n",
            "  Batch   200  of  1,596.    Elapsed: 0:01:30.\n",
            "  Batch   240  of  1,596.    Elapsed: 0:01:48.\n",
            "  Batch   280  of  1,596.    Elapsed: 0:02:05.\n",
            "  Batch   320  of  1,596.    Elapsed: 0:02:23.\n",
            "  Batch   360  of  1,596.    Elapsed: 0:02:41.\n",
            "  Batch   400  of  1,596.    Elapsed: 0:02:59.\n",
            "  Batch   440  of  1,596.    Elapsed: 0:03:17.\n",
            "  Batch   480  of  1,596.    Elapsed: 0:03:35.\n",
            "  Batch   520  of  1,596.    Elapsed: 0:03:53.\n",
            "  Batch   560  of  1,596.    Elapsed: 0:04:11.\n",
            "  Batch   600  of  1,596.    Elapsed: 0:04:29.\n",
            "  Batch   640  of  1,596.    Elapsed: 0:04:47.\n",
            "  Batch   680  of  1,596.    Elapsed: 0:05:05.\n",
            "  Batch   720  of  1,596.    Elapsed: 0:05:23.\n",
            "  Batch   760  of  1,596.    Elapsed: 0:05:41.\n",
            "  Batch   800  of  1,596.    Elapsed: 0:05:58.\n",
            "  Batch   840  of  1,596.    Elapsed: 0:06:16.\n",
            "  Batch   880  of  1,596.    Elapsed: 0:06:34.\n",
            "  Batch   920  of  1,596.    Elapsed: 0:06:52.\n",
            "  Batch   960  of  1,596.    Elapsed: 0:07:10.\n",
            "  Batch 1,000  of  1,596.    Elapsed: 0:07:28.\n",
            "  Batch 1,040  of  1,596.    Elapsed: 0:07:46.\n",
            "  Batch 1,080  of  1,596.    Elapsed: 0:08:04.\n",
            "  Batch 1,120  of  1,596.    Elapsed: 0:08:22.\n",
            "  Batch 1,160  of  1,596.    Elapsed: 0:08:40.\n",
            "  Batch 1,200  of  1,596.    Elapsed: 0:08:58.\n",
            "  Batch 1,240  of  1,596.    Elapsed: 0:09:16.\n",
            "  Batch 1,280  of  1,596.    Elapsed: 0:09:34.\n",
            "  Batch 1,320  of  1,596.    Elapsed: 0:09:51.\n",
            "  Batch 1,360  of  1,596.    Elapsed: 0:10:09.\n",
            "  Batch 1,400  of  1,596.    Elapsed: 0:10:27.\n",
            "  Batch 1,440  of  1,596.    Elapsed: 0:10:45.\n",
            "  Batch 1,480  of  1,596.    Elapsed: 0:11:03.\n",
            "  Batch 1,520  of  1,596.    Elapsed: 0:11:21.\n",
            "  Batch 1,560  of  1,596.    Elapsed: 0:11:39.\n",
            "\n",
            "  Average training loss: 0.65\n",
            "  Training epcoh took: 0:11:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.62\n",
            "  Validation Loss: 0.67\n",
            "  Validation took: 0:00:25\n",
            "\n",
            "======== Epoch 4 / 15 ========\n",
            "Training...\n",
            "  Batch    40  of  1,596.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  1,596.    Elapsed: 0:00:36.\n",
            "  Batch   120  of  1,596.    Elapsed: 0:00:54.\n",
            "  Batch   160  of  1,596.    Elapsed: 0:01:12.\n",
            "  Batch   200  of  1,596.    Elapsed: 0:01:30.\n",
            "  Batch   240  of  1,596.    Elapsed: 0:01:48.\n",
            "  Batch   280  of  1,596.    Elapsed: 0:02:05.\n",
            "  Batch   320  of  1,596.    Elapsed: 0:02:23.\n",
            "  Batch   360  of  1,596.    Elapsed: 0:02:41.\n",
            "  Batch   400  of  1,596.    Elapsed: 0:02:59.\n",
            "  Batch   440  of  1,596.    Elapsed: 0:03:17.\n",
            "  Batch   480  of  1,596.    Elapsed: 0:03:35.\n",
            "  Batch   520  of  1,596.    Elapsed: 0:03:53.\n",
            "  Batch   560  of  1,596.    Elapsed: 0:04:11.\n",
            "  Batch   600  of  1,596.    Elapsed: 0:04:29.\n",
            "  Batch   640  of  1,596.    Elapsed: 0:04:47.\n",
            "  Batch   680  of  1,596.    Elapsed: 0:05:05.\n",
            "  Batch   720  of  1,596.    Elapsed: 0:05:23.\n",
            "  Batch   760  of  1,596.    Elapsed: 0:05:41.\n",
            "  Batch   800  of  1,596.    Elapsed: 0:05:59.\n",
            "  Batch   840  of  1,596.    Elapsed: 0:06:17.\n",
            "  Batch   880  of  1,596.    Elapsed: 0:06:34.\n",
            "  Batch   920  of  1,596.    Elapsed: 0:06:52.\n",
            "  Batch   960  of  1,596.    Elapsed: 0:07:10.\n",
            "  Batch 1,000  of  1,596.    Elapsed: 0:07:28.\n",
            "  Batch 1,040  of  1,596.    Elapsed: 0:07:46.\n",
            "  Batch 1,080  of  1,596.    Elapsed: 0:08:04.\n",
            "  Batch 1,120  of  1,596.    Elapsed: 0:08:22.\n",
            "  Batch 1,160  of  1,596.    Elapsed: 0:08:40.\n",
            "  Batch 1,200  of  1,596.    Elapsed: 0:08:58.\n",
            "  Batch 1,240  of  1,596.    Elapsed: 0:09:16.\n",
            "  Batch 1,280  of  1,596.    Elapsed: 0:09:34.\n",
            "  Batch 1,320  of  1,596.    Elapsed: 0:09:52.\n",
            "  Batch 1,360  of  1,596.    Elapsed: 0:10:10.\n",
            "  Batch 1,400  of  1,596.    Elapsed: 0:10:28.\n",
            "  Batch 1,440  of  1,596.    Elapsed: 0:10:45.\n",
            "  Batch 1,480  of  1,596.    Elapsed: 0:11:03.\n",
            "  Batch 1,520  of  1,596.    Elapsed: 0:11:21.\n",
            "  Batch 1,560  of  1,596.    Elapsed: 0:11:39.\n",
            "\n",
            "  Average training loss: 0.64\n",
            "  Training epcoh took: 0:11:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.70\n",
            "  Validation took: 0:00:25\n",
            "\n",
            "======== Epoch 5 / 15 ========\n",
            "Training...\n",
            "  Batch    40  of  1,596.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  1,596.    Elapsed: 0:00:36.\n",
            "  Batch   120  of  1,596.    Elapsed: 0:00:54.\n",
            "  Batch   160  of  1,596.    Elapsed: 0:01:12.\n",
            "  Batch   200  of  1,596.    Elapsed: 0:01:30.\n",
            "  Batch   240  of  1,596.    Elapsed: 0:01:48.\n",
            "  Batch   280  of  1,596.    Elapsed: 0:02:06.\n",
            "  Batch   320  of  1,596.    Elapsed: 0:02:23.\n",
            "  Batch   360  of  1,596.    Elapsed: 0:02:41.\n",
            "  Batch   400  of  1,596.    Elapsed: 0:02:59.\n",
            "  Batch   440  of  1,596.    Elapsed: 0:03:17.\n",
            "  Batch   480  of  1,596.    Elapsed: 0:03:35.\n",
            "  Batch   520  of  1,596.    Elapsed: 0:03:53.\n",
            "  Batch   560  of  1,596.    Elapsed: 0:04:11.\n",
            "  Batch   600  of  1,596.    Elapsed: 0:04:29.\n",
            "  Batch   640  of  1,596.    Elapsed: 0:04:47.\n",
            "  Batch   680  of  1,596.    Elapsed: 0:05:05.\n",
            "  Batch   720  of  1,596.    Elapsed: 0:05:23.\n",
            "  Batch   760  of  1,596.    Elapsed: 0:05:41.\n",
            "  Batch   800  of  1,596.    Elapsed: 0:05:59.\n",
            "  Batch   840  of  1,596.    Elapsed: 0:06:17.\n",
            "  Batch   880  of  1,596.    Elapsed: 0:06:35.\n",
            "  Batch   920  of  1,596.    Elapsed: 0:06:53.\n",
            "  Batch   960  of  1,596.    Elapsed: 0:07:10.\n",
            "  Batch 1,000  of  1,596.    Elapsed: 0:07:28.\n",
            "  Batch 1,040  of  1,596.    Elapsed: 0:07:46.\n",
            "  Batch 1,080  of  1,596.    Elapsed: 0:08:04.\n",
            "  Batch 1,120  of  1,596.    Elapsed: 0:08:22.\n",
            "  Batch 1,160  of  1,596.    Elapsed: 0:08:40.\n",
            "  Batch 1,200  of  1,596.    Elapsed: 0:08:58.\n",
            "  Batch 1,240  of  1,596.    Elapsed: 0:09:16.\n",
            "  Batch 1,280  of  1,596.    Elapsed: 0:09:34.\n",
            "  Batch 1,320  of  1,596.    Elapsed: 0:09:52.\n",
            "  Batch 1,360  of  1,596.    Elapsed: 0:10:10.\n",
            "  Batch 1,400  of  1,596.    Elapsed: 0:10:28.\n",
            "  Batch 1,440  of  1,596.    Elapsed: 0:10:46.\n",
            "  Batch 1,480  of  1,596.    Elapsed: 0:11:04.\n",
            "  Batch 1,520  of  1,596.    Elapsed: 0:11:22.\n",
            "  Batch 1,560  of  1,596.    Elapsed: 0:11:39.\n",
            "\n",
            "  Average training loss: 0.63\n",
            "  Training epcoh took: 0:11:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.69\n",
            "  Validation took: 0:00:25\n",
            "\n",
            "======== Epoch 6 / 15 ========\n",
            "Training...\n",
            "  Batch    40  of  1,596.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  1,596.    Elapsed: 0:00:36.\n",
            "  Batch   120  of  1,596.    Elapsed: 0:00:54.\n",
            "  Batch   160  of  1,596.    Elapsed: 0:01:12.\n",
            "  Batch   200  of  1,596.    Elapsed: 0:01:30.\n",
            "  Batch   240  of  1,596.    Elapsed: 0:01:48.\n",
            "  Batch   280  of  1,596.    Elapsed: 0:02:05.\n",
            "  Batch   320  of  1,596.    Elapsed: 0:02:23.\n",
            "  Batch   360  of  1,596.    Elapsed: 0:02:41.\n",
            "  Batch   400  of  1,596.    Elapsed: 0:02:59.\n",
            "  Batch   440  of  1,596.    Elapsed: 0:03:17.\n",
            "  Batch   480  of  1,596.    Elapsed: 0:03:35.\n",
            "  Batch   520  of  1,596.    Elapsed: 0:03:53.\n",
            "  Batch   560  of  1,596.    Elapsed: 0:04:11.\n",
            "  Batch   600  of  1,596.    Elapsed: 0:04:29.\n",
            "  Batch   640  of  1,596.    Elapsed: 0:04:47.\n",
            "  Batch   680  of  1,596.    Elapsed: 0:05:05.\n",
            "  Batch   720  of  1,596.    Elapsed: 0:05:23.\n",
            "  Batch   760  of  1,596.    Elapsed: 0:05:41.\n",
            "  Batch   800  of  1,596.    Elapsed: 0:05:59.\n",
            "  Batch   840  of  1,596.    Elapsed: 0:06:17.\n",
            "  Batch   880  of  1,596.    Elapsed: 0:06:34.\n",
            "  Batch   920  of  1,596.    Elapsed: 0:06:52.\n",
            "  Batch   960  of  1,596.    Elapsed: 0:07:10.\n",
            "  Batch 1,000  of  1,596.    Elapsed: 0:07:28.\n",
            "  Batch 1,040  of  1,596.    Elapsed: 0:07:46.\n",
            "  Batch 1,080  of  1,596.    Elapsed: 0:08:04.\n",
            "  Batch 1,120  of  1,596.    Elapsed: 0:08:22.\n",
            "  Batch 1,160  of  1,596.    Elapsed: 0:08:40.\n",
            "  Batch 1,200  of  1,596.    Elapsed: 0:08:58.\n",
            "  Batch 1,240  of  1,596.    Elapsed: 0:09:16.\n",
            "  Batch 1,280  of  1,596.    Elapsed: 0:09:34.\n",
            "  Batch 1,320  of  1,596.    Elapsed: 0:09:52.\n",
            "  Batch 1,360  of  1,596.    Elapsed: 0:10:10.\n",
            "  Batch 1,400  of  1,596.    Elapsed: 0:10:27.\n",
            "  Batch 1,440  of  1,596.    Elapsed: 0:10:45.\n",
            "  Batch 1,480  of  1,596.    Elapsed: 0:11:03.\n",
            "  Batch 1,520  of  1,596.    Elapsed: 0:11:21.\n",
            "  Batch 1,560  of  1,596.    Elapsed: 0:11:39.\n",
            "\n",
            "  Average training loss: 0.62\n",
            "  Training epcoh took: 0:11:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.69\n",
            "  Validation took: 0:00:25\n",
            "\n",
            "======== Epoch 7 / 15 ========\n",
            "Training...\n",
            "  Batch    40  of  1,596.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  1,596.    Elapsed: 0:00:36.\n",
            "  Batch   120  of  1,596.    Elapsed: 0:00:54.\n",
            "  Batch   160  of  1,596.    Elapsed: 0:01:12.\n",
            "  Batch   200  of  1,596.    Elapsed: 0:01:30.\n",
            "  Batch   240  of  1,596.    Elapsed: 0:01:48.\n",
            "  Batch   280  of  1,596.    Elapsed: 0:02:05.\n",
            "  Batch   320  of  1,596.    Elapsed: 0:02:23.\n",
            "  Batch   360  of  1,596.    Elapsed: 0:02:41.\n",
            "  Batch   400  of  1,596.    Elapsed: 0:02:59.\n",
            "  Batch   440  of  1,596.    Elapsed: 0:03:17.\n",
            "  Batch   480  of  1,596.    Elapsed: 0:03:35.\n",
            "  Batch   520  of  1,596.    Elapsed: 0:03:53.\n",
            "  Batch   560  of  1,596.    Elapsed: 0:04:11.\n",
            "  Batch   600  of  1,596.    Elapsed: 0:04:29.\n",
            "  Batch   640  of  1,596.    Elapsed: 0:04:47.\n",
            "  Batch   680  of  1,596.    Elapsed: 0:05:05.\n",
            "  Batch   720  of  1,596.    Elapsed: 0:05:23.\n",
            "  Batch   760  of  1,596.    Elapsed: 0:05:40.\n",
            "  Batch   800  of  1,596.    Elapsed: 0:05:58.\n",
            "  Batch   840  of  1,596.    Elapsed: 0:06:16.\n",
            "  Batch   880  of  1,596.    Elapsed: 0:06:34.\n",
            "  Batch   920  of  1,596.    Elapsed: 0:06:52.\n",
            "  Batch   960  of  1,596.    Elapsed: 0:07:10.\n",
            "  Batch 1,000  of  1,596.    Elapsed: 0:07:28.\n",
            "  Batch 1,040  of  1,596.    Elapsed: 0:07:46.\n",
            "  Batch 1,080  of  1,596.    Elapsed: 0:08:04.\n",
            "  Batch 1,120  of  1,596.    Elapsed: 0:08:22.\n",
            "  Batch 1,160  of  1,596.    Elapsed: 0:08:40.\n",
            "  Batch 1,200  of  1,596.    Elapsed: 0:08:58.\n",
            "  Batch 1,240  of  1,596.    Elapsed: 0:09:16.\n",
            "  Batch 1,280  of  1,596.    Elapsed: 0:09:33.\n",
            "  Batch 1,320  of  1,596.    Elapsed: 0:09:51.\n",
            "  Batch 1,360  of  1,596.    Elapsed: 0:10:09.\n",
            "  Batch 1,400  of  1,596.    Elapsed: 0:10:27.\n",
            "  Batch 1,440  of  1,596.    Elapsed: 0:10:45.\n",
            "  Batch 1,480  of  1,596.    Elapsed: 0:11:03.\n",
            "  Batch 1,520  of  1,596.    Elapsed: 0:11:21.\n",
            "  Batch 1,560  of  1,596.    Elapsed: 0:11:39.\n",
            "\n",
            "  Average training loss: 0.60\n",
            "  Training epcoh took: 0:11:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.60\n",
            "  Validation Loss: 0.72\n",
            "  Validation took: 0:00:25\n",
            "\n",
            "======== Epoch 8 / 15 ========\n",
            "Training...\n",
            "  Batch    40  of  1,596.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  1,596.    Elapsed: 0:00:36.\n",
            "  Batch   120  of  1,596.    Elapsed: 0:00:54.\n",
            "  Batch   160  of  1,596.    Elapsed: 0:01:12.\n",
            "  Batch   200  of  1,596.    Elapsed: 0:01:30.\n",
            "  Batch   240  of  1,596.    Elapsed: 0:01:48.\n",
            "  Batch   280  of  1,596.    Elapsed: 0:02:06.\n",
            "  Batch   320  of  1,596.    Elapsed: 0:02:24.\n",
            "  Batch   360  of  1,596.    Elapsed: 0:02:42.\n",
            "  Batch   400  of  1,596.    Elapsed: 0:03:00.\n",
            "  Batch   440  of  1,596.    Elapsed: 0:03:18.\n",
            "  Batch   480  of  1,596.    Elapsed: 0:03:36.\n",
            "  Batch   520  of  1,596.    Elapsed: 0:03:54.\n",
            "  Batch   560  of  1,596.    Elapsed: 0:04:12.\n",
            "  Batch   600  of  1,596.    Elapsed: 0:04:30.\n",
            "  Batch   640  of  1,596.    Elapsed: 0:04:48.\n",
            "  Batch   680  of  1,596.    Elapsed: 0:05:06.\n",
            "  Batch   720  of  1,596.    Elapsed: 0:05:24.\n",
            "  Batch   760  of  1,596.    Elapsed: 0:05:42.\n",
            "  Batch   800  of  1,596.    Elapsed: 0:06:00.\n",
            "  Batch   840  of  1,596.    Elapsed: 0:06:18.\n",
            "  Batch   880  of  1,596.    Elapsed: 0:06:35.\n",
            "  Batch   920  of  1,596.    Elapsed: 0:06:53.\n",
            "  Batch   960  of  1,596.    Elapsed: 0:07:11.\n",
            "  Batch 1,000  of  1,596.    Elapsed: 0:07:29.\n",
            "  Batch 1,040  of  1,596.    Elapsed: 0:07:47.\n",
            "  Batch 1,080  of  1,596.    Elapsed: 0:08:05.\n",
            "  Batch 1,120  of  1,596.    Elapsed: 0:08:23.\n",
            "  Batch 1,160  of  1,596.    Elapsed: 0:08:41.\n",
            "  Batch 1,200  of  1,596.    Elapsed: 0:08:59.\n",
            "  Batch 1,240  of  1,596.    Elapsed: 0:09:17.\n",
            "  Batch 1,280  of  1,596.    Elapsed: 0:09:35.\n",
            "  Batch 1,320  of  1,596.    Elapsed: 0:09:53.\n",
            "  Batch 1,360  of  1,596.    Elapsed: 0:10:11.\n",
            "  Batch 1,400  of  1,596.    Elapsed: 0:10:29.\n",
            "  Batch 1,440  of  1,596.    Elapsed: 0:10:47.\n",
            "  Batch 1,480  of  1,596.    Elapsed: 0:11:05.\n",
            "  Batch 1,520  of  1,596.    Elapsed: 0:11:23.\n",
            "  Batch 1,560  of  1,596.    Elapsed: 0:11:41.\n",
            "\n",
            "  Average training loss: 0.59\n",
            "  Training epcoh took: 0:11:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.77\n",
            "  Validation took: 0:00:26\n",
            "\n",
            "======== Epoch 9 / 15 ========\n",
            "Training...\n",
            "  Batch    40  of  1,596.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  1,596.    Elapsed: 0:00:36.\n",
            "  Batch   120  of  1,596.    Elapsed: 0:00:54.\n",
            "  Batch   160  of  1,596.    Elapsed: 0:01:12.\n",
            "  Batch   200  of  1,596.    Elapsed: 0:01:30.\n",
            "  Batch   240  of  1,596.    Elapsed: 0:01:48.\n",
            "  Batch   280  of  1,596.    Elapsed: 0:02:06.\n",
            "  Batch   320  of  1,596.    Elapsed: 0:02:24.\n",
            "  Batch   360  of  1,596.    Elapsed: 0:02:42.\n",
            "  Batch   400  of  1,596.    Elapsed: 0:03:00.\n",
            "  Batch   440  of  1,596.    Elapsed: 0:03:18.\n",
            "  Batch   480  of  1,596.    Elapsed: 0:03:37.\n",
            "  Batch   520  of  1,596.    Elapsed: 0:03:55.\n",
            "  Batch   560  of  1,596.    Elapsed: 0:04:13.\n",
            "  Batch   600  of  1,596.    Elapsed: 0:04:31.\n",
            "  Batch   640  of  1,596.    Elapsed: 0:04:49.\n",
            "  Batch   680  of  1,596.    Elapsed: 0:05:07.\n",
            "  Batch   720  of  1,596.    Elapsed: 0:05:25.\n",
            "  Batch   760  of  1,596.    Elapsed: 0:05:43.\n",
            "  Batch   800  of  1,596.    Elapsed: 0:06:01.\n",
            "  Batch   840  of  1,596.    Elapsed: 0:06:19.\n",
            "  Batch   880  of  1,596.    Elapsed: 0:06:37.\n",
            "  Batch   920  of  1,596.    Elapsed: 0:06:55.\n",
            "  Batch   960  of  1,596.    Elapsed: 0:07:13.\n",
            "  Batch 1,000  of  1,596.    Elapsed: 0:07:31.\n",
            "  Batch 1,040  of  1,596.    Elapsed: 0:07:49.\n",
            "  Batch 1,080  of  1,596.    Elapsed: 0:08:07.\n",
            "  Batch 1,120  of  1,596.    Elapsed: 0:08:25.\n",
            "  Batch 1,160  of  1,596.    Elapsed: 0:08:43.\n",
            "  Batch 1,200  of  1,596.    Elapsed: 0:09:01.\n",
            "  Batch 1,240  of  1,596.    Elapsed: 0:09:19.\n",
            "  Batch 1,280  of  1,596.    Elapsed: 0:09:37.\n",
            "  Batch 1,320  of  1,596.    Elapsed: 0:09:55.\n",
            "  Batch 1,360  of  1,596.    Elapsed: 0:10:13.\n",
            "  Batch 1,400  of  1,596.    Elapsed: 0:10:31.\n",
            "  Batch 1,440  of  1,596.    Elapsed: 0:10:49.\n",
            "  Batch 1,480  of  1,596.    Elapsed: 0:11:07.\n",
            "  Batch 1,520  of  1,596.    Elapsed: 0:11:25.\n",
            "  Batch 1,560  of  1,596.    Elapsed: 0:11:43.\n",
            "\n",
            "  Average training loss: 0.57\n",
            "  Training epcoh took: 0:12:00\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.60\n",
            "  Validation Loss: 0.79\n",
            "  Validation took: 0:00:26\n",
            "\n",
            "======== Epoch 10 / 15 ========\n",
            "Training...\n",
            "  Batch    40  of  1,596.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  1,596.    Elapsed: 0:00:36.\n",
            "  Batch   120  of  1,596.    Elapsed: 0:00:54.\n",
            "  Batch   160  of  1,596.    Elapsed: 0:01:12.\n",
            "  Batch   200  of  1,596.    Elapsed: 0:01:30.\n",
            "  Batch   240  of  1,596.    Elapsed: 0:01:48.\n",
            "  Batch   280  of  1,596.    Elapsed: 0:02:06.\n",
            "  Batch   320  of  1,596.    Elapsed: 0:02:24.\n",
            "  Batch   360  of  1,596.    Elapsed: 0:02:42.\n",
            "  Batch   400  of  1,596.    Elapsed: 0:03:00.\n",
            "  Batch   440  of  1,596.    Elapsed: 0:03:18.\n",
            "  Batch   480  of  1,596.    Elapsed: 0:03:36.\n",
            "  Batch   520  of  1,596.    Elapsed: 0:03:54.\n",
            "  Batch   560  of  1,596.    Elapsed: 0:04:13.\n",
            "  Batch   600  of  1,596.    Elapsed: 0:04:31.\n",
            "  Batch   640  of  1,596.    Elapsed: 0:04:49.\n",
            "  Batch   680  of  1,596.    Elapsed: 0:05:07.\n",
            "  Batch   720  of  1,596.    Elapsed: 0:05:25.\n",
            "  Batch   760  of  1,596.    Elapsed: 0:05:43.\n",
            "  Batch   800  of  1,596.    Elapsed: 0:06:01.\n",
            "  Batch   840  of  1,596.    Elapsed: 0:06:19.\n",
            "  Batch   880  of  1,596.    Elapsed: 0:06:37.\n",
            "  Batch   920  of  1,596.    Elapsed: 0:06:55.\n",
            "  Batch   960  of  1,596.    Elapsed: 0:07:13.\n",
            "  Batch 1,000  of  1,596.    Elapsed: 0:07:31.\n",
            "  Batch 1,040  of  1,596.    Elapsed: 0:07:49.\n",
            "  Batch 1,080  of  1,596.    Elapsed: 0:08:07.\n",
            "  Batch 1,120  of  1,596.    Elapsed: 0:08:25.\n",
            "  Batch 1,160  of  1,596.    Elapsed: 0:08:43.\n",
            "  Batch 1,200  of  1,596.    Elapsed: 0:09:01.\n",
            "  Batch 1,240  of  1,596.    Elapsed: 0:09:19.\n",
            "  Batch 1,280  of  1,596.    Elapsed: 0:09:37.\n",
            "  Batch 1,320  of  1,596.    Elapsed: 0:09:55.\n",
            "  Batch 1,360  of  1,596.    Elapsed: 0:10:13.\n",
            "  Batch 1,400  of  1,596.    Elapsed: 0:10:31.\n",
            "  Batch 1,440  of  1,596.    Elapsed: 0:10:49.\n",
            "  Batch 1,480  of  1,596.    Elapsed: 0:11:07.\n",
            "  Batch 1,520  of  1,596.    Elapsed: 0:11:25.\n",
            "  Batch 1,560  of  1,596.    Elapsed: 0:11:43.\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epcoh took: 0:11:59\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.62\n",
            "  Validation Loss: 0.81\n",
            "  Validation took: 0:00:25\n",
            "\n",
            "======== Epoch 11 / 15 ========\n",
            "Training...\n",
            "  Batch    40  of  1,596.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  1,596.    Elapsed: 0:00:36.\n",
            "  Batch   120  of  1,596.    Elapsed: 0:00:54.\n",
            "  Batch   160  of  1,596.    Elapsed: 0:01:12.\n",
            "  Batch   200  of  1,596.    Elapsed: 0:01:30.\n",
            "  Batch   240  of  1,596.    Elapsed: 0:01:47.\n",
            "  Batch   280  of  1,596.    Elapsed: 0:02:05.\n",
            "  Batch   320  of  1,596.    Elapsed: 0:02:23.\n",
            "  Batch   360  of  1,596.    Elapsed: 0:02:41.\n",
            "  Batch   400  of  1,596.    Elapsed: 0:02:59.\n",
            "  Batch   440  of  1,596.    Elapsed: 0:03:17.\n",
            "  Batch   480  of  1,596.    Elapsed: 0:03:35.\n",
            "  Batch   520  of  1,596.    Elapsed: 0:03:53.\n",
            "  Batch   560  of  1,596.    Elapsed: 0:04:11.\n",
            "  Batch   600  of  1,596.    Elapsed: 0:04:29.\n",
            "  Batch   640  of  1,596.    Elapsed: 0:04:47.\n",
            "  Batch   680  of  1,596.    Elapsed: 0:05:05.\n",
            "  Batch   720  of  1,596.    Elapsed: 0:05:22.\n",
            "  Batch   760  of  1,596.    Elapsed: 0:05:40.\n",
            "  Batch   800  of  1,596.    Elapsed: 0:05:58.\n",
            "  Batch   840  of  1,596.    Elapsed: 0:06:16.\n",
            "  Batch   880  of  1,596.    Elapsed: 0:06:34.\n",
            "  Batch   920  of  1,596.    Elapsed: 0:06:52.\n",
            "  Batch   960  of  1,596.    Elapsed: 0:07:10.\n",
            "  Batch 1,000  of  1,596.    Elapsed: 0:07:28.\n",
            "  Batch 1,040  of  1,596.    Elapsed: 0:07:46.\n",
            "  Batch 1,080  of  1,596.    Elapsed: 0:08:04.\n",
            "  Batch 1,120  of  1,596.    Elapsed: 0:08:22.\n",
            "  Batch 1,160  of  1,596.    Elapsed: 0:08:40.\n",
            "  Batch 1,200  of  1,596.    Elapsed: 0:08:58.\n",
            "  Batch 1,240  of  1,596.    Elapsed: 0:09:16.\n",
            "  Batch 1,280  of  1,596.    Elapsed: 0:09:34.\n",
            "  Batch 1,320  of  1,596.    Elapsed: 0:09:52.\n",
            "  Batch 1,360  of  1,596.    Elapsed: 0:10:09.\n",
            "  Batch 1,400  of  1,596.    Elapsed: 0:10:27.\n",
            "  Batch 1,440  of  1,596.    Elapsed: 0:10:45.\n",
            "  Batch 1,480  of  1,596.    Elapsed: 0:11:03.\n",
            "  Batch 1,520  of  1,596.    Elapsed: 0:11:21.\n",
            "  Batch 1,560  of  1,596.    Elapsed: 0:11:39.\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Training epcoh took: 0:11:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.62\n",
            "  Validation Loss: 0.83\n",
            "  Validation took: 0:00:25\n",
            "\n",
            "======== Epoch 12 / 15 ========\n",
            "Training...\n",
            "  Batch    40  of  1,596.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  1,596.    Elapsed: 0:00:36.\n",
            "  Batch   120  of  1,596.    Elapsed: 0:00:54.\n",
            "  Batch   160  of  1,596.    Elapsed: 0:01:12.\n",
            "  Batch   200  of  1,596.    Elapsed: 0:01:30.\n",
            "  Batch   240  of  1,596.    Elapsed: 0:01:48.\n",
            "  Batch   280  of  1,596.    Elapsed: 0:02:05.\n",
            "  Batch   320  of  1,596.    Elapsed: 0:02:23.\n",
            "  Batch   360  of  1,596.    Elapsed: 0:02:41.\n",
            "  Batch   400  of  1,596.    Elapsed: 0:02:59.\n",
            "  Batch   440  of  1,596.    Elapsed: 0:03:17.\n",
            "  Batch   480  of  1,596.    Elapsed: 0:03:35.\n",
            "  Batch   520  of  1,596.    Elapsed: 0:03:53.\n",
            "  Batch   560  of  1,596.    Elapsed: 0:04:11.\n",
            "  Batch   600  of  1,596.    Elapsed: 0:04:29.\n",
            "  Batch   640  of  1,596.    Elapsed: 0:04:47.\n",
            "  Batch   680  of  1,596.    Elapsed: 0:05:05.\n",
            "  Batch   720  of  1,596.    Elapsed: 0:05:23.\n",
            "  Batch   760  of  1,596.    Elapsed: 0:05:41.\n",
            "  Batch   800  of  1,596.    Elapsed: 0:05:58.\n",
            "  Batch   840  of  1,596.    Elapsed: 0:06:16.\n",
            "  Batch   880  of  1,596.    Elapsed: 0:06:34.\n",
            "  Batch   920  of  1,596.    Elapsed: 0:06:52.\n",
            "  Batch   960  of  1,596.    Elapsed: 0:07:10.\n",
            "  Batch 1,000  of  1,596.    Elapsed: 0:07:28.\n",
            "  Batch 1,040  of  1,596.    Elapsed: 0:07:46.\n",
            "  Batch 1,080  of  1,596.    Elapsed: 0:08:04.\n",
            "  Batch 1,120  of  1,596.    Elapsed: 0:08:22.\n",
            "  Batch 1,160  of  1,596.    Elapsed: 0:08:40.\n",
            "  Batch 1,200  of  1,596.    Elapsed: 0:08:58.\n",
            "  Batch 1,240  of  1,596.    Elapsed: 0:09:16.\n",
            "  Batch 1,280  of  1,596.    Elapsed: 0:09:34.\n",
            "  Batch 1,320  of  1,596.    Elapsed: 0:09:52.\n",
            "  Batch 1,360  of  1,596.    Elapsed: 0:10:10.\n",
            "  Batch 1,400  of  1,596.    Elapsed: 0:10:27.\n",
            "  Batch 1,440  of  1,596.    Elapsed: 0:10:45.\n",
            "  Batch 1,480  of  1,596.    Elapsed: 0:11:03.\n",
            "  Batch 1,520  of  1,596.    Elapsed: 0:11:21.\n",
            "  Batch 1,560  of  1,596.    Elapsed: 0:11:39.\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epcoh took: 0:11:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.85\n",
            "  Validation took: 0:00:25\n",
            "\n",
            "======== Epoch 13 / 15 ========\n",
            "Training...\n",
            "  Batch    40  of  1,596.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  1,596.    Elapsed: 0:00:36.\n",
            "  Batch   120  of  1,596.    Elapsed: 0:00:54.\n",
            "  Batch   160  of  1,596.    Elapsed: 0:01:12.\n",
            "  Batch   200  of  1,596.    Elapsed: 0:01:30.\n",
            "  Batch   240  of  1,596.    Elapsed: 0:01:48.\n",
            "  Batch   280  of  1,596.    Elapsed: 0:02:05.\n",
            "  Batch   320  of  1,596.    Elapsed: 0:02:23.\n",
            "  Batch   360  of  1,596.    Elapsed: 0:02:41.\n",
            "  Batch   400  of  1,596.    Elapsed: 0:02:59.\n",
            "  Batch   440  of  1,596.    Elapsed: 0:03:17.\n",
            "  Batch   480  of  1,596.    Elapsed: 0:03:35.\n",
            "  Batch   520  of  1,596.    Elapsed: 0:03:53.\n",
            "  Batch   560  of  1,596.    Elapsed: 0:04:11.\n",
            "  Batch   600  of  1,596.    Elapsed: 0:04:29.\n",
            "  Batch   640  of  1,596.    Elapsed: 0:04:47.\n",
            "  Batch   680  of  1,596.    Elapsed: 0:05:05.\n",
            "  Batch   720  of  1,596.    Elapsed: 0:05:23.\n",
            "  Batch   760  of  1,596.    Elapsed: 0:05:41.\n",
            "  Batch   800  of  1,596.    Elapsed: 0:05:59.\n",
            "  Batch   840  of  1,596.    Elapsed: 0:06:17.\n",
            "  Batch   880  of  1,596.    Elapsed: 0:06:35.\n",
            "  Batch   920  of  1,596.    Elapsed: 0:06:52.\n",
            "  Batch   960  of  1,596.    Elapsed: 0:07:10.\n",
            "  Batch 1,000  of  1,596.    Elapsed: 0:07:28.\n",
            "  Batch 1,040  of  1,596.    Elapsed: 0:07:46.\n",
            "  Batch 1,080  of  1,596.    Elapsed: 0:08:04.\n",
            "  Batch 1,120  of  1,596.    Elapsed: 0:08:22.\n",
            "  Batch 1,160  of  1,596.    Elapsed: 0:08:40.\n",
            "  Batch 1,200  of  1,596.    Elapsed: 0:08:58.\n",
            "  Batch 1,240  of  1,596.    Elapsed: 0:09:16.\n",
            "  Batch 1,280  of  1,596.    Elapsed: 0:09:34.\n",
            "  Batch 1,320  of  1,596.    Elapsed: 0:09:52.\n",
            "  Batch 1,360  of  1,596.    Elapsed: 0:10:10.\n",
            "  Batch 1,400  of  1,596.    Elapsed: 0:10:28.\n",
            "  Batch 1,440  of  1,596.    Elapsed: 0:10:46.\n",
            "  Batch 1,480  of  1,596.    Elapsed: 0:11:04.\n",
            "  Batch 1,520  of  1,596.    Elapsed: 0:11:22.\n",
            "  Batch 1,560  of  1,596.    Elapsed: 0:11:40.\n",
            "\n",
            "  Average training loss: 0.47\n",
            "  Training epcoh took: 0:11:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.94\n",
            "  Validation took: 0:00:25\n",
            "\n",
            "======== Epoch 14 / 15 ========\n",
            "Training...\n",
            "  Batch    40  of  1,596.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  1,596.    Elapsed: 0:00:36.\n",
            "  Batch   120  of  1,596.    Elapsed: 0:00:54.\n",
            "  Batch   160  of  1,596.    Elapsed: 0:01:12.\n",
            "  Batch   200  of  1,596.    Elapsed: 0:01:30.\n",
            "  Batch   240  of  1,596.    Elapsed: 0:01:48.\n",
            "  Batch   280  of  1,596.    Elapsed: 0:02:06.\n",
            "  Batch   320  of  1,596.    Elapsed: 0:02:24.\n",
            "  Batch   360  of  1,596.    Elapsed: 0:02:42.\n",
            "  Batch   400  of  1,596.    Elapsed: 0:03:00.\n",
            "  Batch   440  of  1,596.    Elapsed: 0:03:18.\n",
            "  Batch   480  of  1,596.    Elapsed: 0:03:36.\n",
            "  Batch   520  of  1,596.    Elapsed: 0:03:54.\n",
            "  Batch   560  of  1,596.    Elapsed: 0:04:12.\n",
            "  Batch   600  of  1,596.    Elapsed: 0:04:29.\n",
            "  Batch   640  of  1,596.    Elapsed: 0:04:47.\n",
            "  Batch   680  of  1,596.    Elapsed: 0:05:05.\n",
            "  Batch   720  of  1,596.    Elapsed: 0:05:23.\n",
            "  Batch   760  of  1,596.    Elapsed: 0:05:41.\n",
            "  Batch   800  of  1,596.    Elapsed: 0:05:59.\n",
            "  Batch   840  of  1,596.    Elapsed: 0:06:17.\n",
            "  Batch   880  of  1,596.    Elapsed: 0:06:35.\n",
            "  Batch   920  of  1,596.    Elapsed: 0:06:53.\n",
            "  Batch   960  of  1,596.    Elapsed: 0:07:11.\n",
            "  Batch 1,000  of  1,596.    Elapsed: 0:07:29.\n",
            "  Batch 1,040  of  1,596.    Elapsed: 0:07:47.\n",
            "  Batch 1,080  of  1,596.    Elapsed: 0:08:05.\n",
            "  Batch 1,120  of  1,596.    Elapsed: 0:08:23.\n",
            "  Batch 1,160  of  1,596.    Elapsed: 0:08:41.\n",
            "  Batch 1,200  of  1,596.    Elapsed: 0:08:59.\n",
            "  Batch 1,240  of  1,596.    Elapsed: 0:09:17.\n",
            "  Batch 1,280  of  1,596.    Elapsed: 0:09:35.\n",
            "  Batch 1,320  of  1,596.    Elapsed: 0:09:53.\n",
            "  Batch 1,360  of  1,596.    Elapsed: 0:10:11.\n",
            "  Batch 1,400  of  1,596.    Elapsed: 0:10:29.\n",
            "  Batch 1,440  of  1,596.    Elapsed: 0:10:47.\n",
            "  Batch 1,480  of  1,596.    Elapsed: 0:11:05.\n",
            "  Batch 1,520  of  1,596.    Elapsed: 0:11:23.\n",
            "  Batch 1,560  of  1,596.    Elapsed: 0:11:41.\n",
            "\n",
            "  Average training loss: 0.44\n",
            "  Training epcoh took: 0:11:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.96\n",
            "  Validation took: 0:00:25\n",
            "\n",
            "======== Epoch 15 / 15 ========\n",
            "Training...\n",
            "  Batch    40  of  1,596.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  1,596.    Elapsed: 0:00:36.\n",
            "  Batch   120  of  1,596.    Elapsed: 0:00:54.\n",
            "  Batch   160  of  1,596.    Elapsed: 0:01:12.\n",
            "  Batch   200  of  1,596.    Elapsed: 0:01:30.\n",
            "  Batch   240  of  1,596.    Elapsed: 0:01:48.\n",
            "  Batch   280  of  1,596.    Elapsed: 0:02:06.\n",
            "  Batch   320  of  1,596.    Elapsed: 0:02:24.\n",
            "  Batch   360  of  1,596.    Elapsed: 0:02:42.\n",
            "  Batch   400  of  1,596.    Elapsed: 0:03:00.\n",
            "  Batch   440  of  1,596.    Elapsed: 0:03:18.\n",
            "  Batch   480  of  1,596.    Elapsed: 0:03:36.\n",
            "  Batch   520  of  1,596.    Elapsed: 0:03:54.\n",
            "  Batch   560  of  1,596.    Elapsed: 0:04:12.\n",
            "  Batch   600  of  1,596.    Elapsed: 0:04:30.\n",
            "  Batch   640  of  1,596.    Elapsed: 0:04:48.\n",
            "  Batch   680  of  1,596.    Elapsed: 0:05:06.\n",
            "  Batch   720  of  1,596.    Elapsed: 0:05:24.\n",
            "  Batch   760  of  1,596.    Elapsed: 0:05:42.\n",
            "  Batch   800  of  1,596.    Elapsed: 0:06:00.\n",
            "  Batch   840  of  1,596.    Elapsed: 0:06:18.\n",
            "  Batch   880  of  1,596.    Elapsed: 0:06:36.\n",
            "  Batch   920  of  1,596.    Elapsed: 0:06:54.\n",
            "  Batch   960  of  1,596.    Elapsed: 0:07:12.\n",
            "  Batch 1,000  of  1,596.    Elapsed: 0:07:30.\n",
            "  Batch 1,040  of  1,596.    Elapsed: 0:07:48.\n",
            "  Batch 1,080  of  1,596.    Elapsed: 0:08:06.\n",
            "  Batch 1,120  of  1,596.    Elapsed: 0:08:24.\n",
            "  Batch 1,160  of  1,596.    Elapsed: 0:08:42.\n",
            "  Batch 1,200  of  1,596.    Elapsed: 0:09:00.\n",
            "  Batch 1,240  of  1,596.    Elapsed: 0:09:18.\n",
            "  Batch 1,280  of  1,596.    Elapsed: 0:09:36.\n",
            "  Batch 1,320  of  1,596.    Elapsed: 0:09:54.\n",
            "  Batch 1,360  of  1,596.    Elapsed: 0:10:11.\n",
            "  Batch 1,400  of  1,596.    Elapsed: 0:10:29.\n",
            "  Batch 1,440  of  1,596.    Elapsed: 0:10:47.\n",
            "  Batch 1,480  of  1,596.    Elapsed: 0:11:05.\n",
            "  Batch 1,520  of  1,596.    Elapsed: 0:11:23.\n",
            "  Batch 1,560  of  1,596.    Elapsed: 0:11:41.\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epcoh took: 0:11:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.98\n",
            "  Validation took: 0:00:25\n",
            "\n",
            "Training complete!\n",
            "Total training took 3:05:26 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K7_yY_aVRst"
      },
      "source": [
        "def get_Data_Pred(data_json_file1):\r\n",
        "    X, Y = [], []\r\n",
        "    with open(data_json_file1, 'r') as json_file:\r\n",
        "        json_list = list(json_file)\r\n",
        "        #print(json_list[0])\r\n",
        "        for json_str in json_list:\r\n",
        "            item = json.loads(json_str)\r\n",
        "            text = item['passage']['text']\r\n",
        "            #print(item['passage'].keys())\r\n",
        "            questions = item['passage']['questions']\r\n",
        "            for q in questions:\r\n",
        "                query = q['question']\r\n",
        "                ans = q['answers']\r\n",
        "                for a in ans:\r\n",
        "                  if len(text) <= 512:\r\n",
        "                    text_n = text\r\n",
        "                  else:\r\n",
        "                    text_n = text[-542:]   \r\n",
        "                  qw = query[:-1] if query[-1]==\".\" else query\r\n",
        "                  txt = a[\"text\"][:-1] if a[\"text\"][-1] == \".\" else a[\"text\"] \r\n",
        "                  X.append(\"[CLS]\" +text_n+ \"[SEP] \" +qw+ \" \" +txt)                         \r\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M765_G5UVRsu"
      },
      "source": [
        "Pred = get_Data_Pred(\"/content/test.jsonl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P4-9jYJlX4L"
      },
      "source": [
        "torch.cuda.set_device(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKBYFQlJmSJg"
      },
      "source": [
        "model = model.to(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ektBJOGMnJAC"
      },
      "source": [
        "model = torch.nn.DataParallel(model.cuda(), device_ids=[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0p7H4z0Yh1B"
      },
      "source": [
        "BERT = []\r\n",
        "for el in Pred:\r\n",
        "  try:\r\n",
        "    token = tokenizer(el, return_tensors=\"pt\")\r\n",
        "    out = model(**token)\r\n",
        "    i = list(map(float, str(out)[11:-48].split(',')))\r\n",
        "    BERT.append(i)\r\n",
        "  except:\r\n",
        "    print(el)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLVOXzYr4UeS"
      },
      "source": [
        "file = open(\"out.txt\", \"w\")\r\n",
        "for el in BERT:\r\n",
        "  file.write(str(el) + '\\n')\r\n",
        "file.close()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUmvCr4dn0_P"
      },
      "source": [
        "A = []\r\n",
        "for i in BERT:\r\n",
        "   if i[1] > 1:\r\n",
        "      A.append(1)\r\n",
        "   else:\r\n",
        "      A.append(0)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMSmb-LDT6zD",
        "outputId": "45bf7ae8-1fe8-42c3-a0ed-35dcccfea7f9"
      },
      "source": [
        "from pprint import pprint\r\n",
        "pprint(BERT[:8])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.2891, 1.096],\n",
            " [1.2856, 1.093],\n",
            " [1.0879, -0.791],\n",
            " [1.1477, -0.848],\n",
            " [1.4167, -1.086],\n",
            " [1.2944, -0.98],\n",
            " [1.2768, -0.965],\n",
            " [0.7381, 0.676]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlp0TFfChdDF"
      },
      "source": [
        "def raz(r):\r\n",
        "  if r == 1:\r\n",
        "    return 0\r\n",
        "  return 1  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu9ZGYKEP4Vj"
      },
      "source": [
        "All_Dict = []\r\n",
        "i = 0\r\n",
        "with jsonlines.open('test.jsonl') as reader:\r\n",
        "    for jsn in reader:\r\n",
        "        Main_Dict = dict()\r\n",
        "        passage = jsn[\"passage\"]\r\n",
        "        Main_Dict['idx'] = jsn[\"idx\"]\r\n",
        "        Passage = dict()\r\n",
        "        Passage[\"text\"] = str(passage[\"text\"])\r\n",
        "        out2_arr = []\r\n",
        "        for ques in passage[\"questions\"]:\r\n",
        "            qu = dict()\r\n",
        "            qu[\"question\"] = str(ques[\"question\"])\r\n",
        "            answers = ques[\"answers\"]\r\n",
        "            out3_arr = []\r\n",
        "            for el in answers:\r\n",
        "                out3 = dict()\r\n",
        "                out3[\"idx\"] = el[\"idx\"]\r\n",
        "                out3[\"text\"] = str(el[\"text\"])\r\n",
        "                out3[\"label\"] = raz(A[i])\r\n",
        "                #out3[\"label\"] = A[i]\r\n",
        "                out3_arr.append(out3)\r\n",
        "                i += 1\r\n",
        "            qu[\"answers\"] = out3_arr\r\n",
        "            qu[\"idx\"] = ques[\"idx\"]\r\n",
        "            out2_arr.append(qu)\r\n",
        "        Passage[\"questions\"] = out2_arr\r\n",
        "        Main_Dict[\"passage\"] = Passage\r\n",
        "        jn = str(Main_Dict)\r\n",
        "        #print(jn)\r\n",
        "        All_Dict.append(Main_Dict)\r\n",
        "with jsonlines.open('output.jsonl', 'w') as writer:\r\n",
        "    writer.write_all(All_Dict)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}